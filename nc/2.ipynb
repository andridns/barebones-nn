{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnets import weight_init\n",
    "from dnets.utils import init_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_param_init(model, random_seed=42):\n",
    "    \"\"\"Initialize weight and biases parameters in the network.\n",
    "\n",
    "    Args:\n",
    "        model['layer_dims']: list containing number of input, hidden and output neurons in sequence\n",
    "        model['weight_init'] (str): weight initialization method\n",
    "    \n",
    "    Returns:\n",
    "        model['var']: dictionary of model weights (W) and biases (b) in all layers\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    initializer = model['weight_init']\n",
    "    ndims = model['layer_dims']\n",
    "    model['var'] = {}\n",
    "    print(weight_init, type(weight_init))\n",
    "    L = len(ndims) # no of layers\n",
    "    for l in range(1, L):\n",
    "        model['var']['b' + str(l)] = np.zeros((1, model['layer_dims'][l])) # bias initialization\n",
    "        model['var']['W' + str(l)] = getattr(weight_init, f'{initializer}')(ndims[l-1], ndims[l])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'dnets.weight_init' from '/home/andrinusasmita/barebones-nn/nc/dnets/weight_init.py'> <class 'module'>\n"
     ]
    }
   ],
   "source": [
    "layer_dims = [4, 32, 64, 4]\n",
    "model = {}\n",
    "model = init_model(layer_dims=layer_dims,\n",
    "                          activation='RELU', weight_init='GLOROT_UNiform',\n",
    "                          dropout_rate=None, learning_rate=0.001, num_steps=3000, \n",
    "                          early_stopping=True)\n",
    "model = global_param_init(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer_dims': [4, 32, 64, 4],\n",
       " 'activation': 'relu',\n",
       " 'weight_init': 'glorot_uniform',\n",
       " 'dropout_rate': None,\n",
       " 'learning_rate': 0.001,\n",
       " 'num_steps': 3000,\n",
       " 'early_stopping': True,\n",
       " 'var': {'b1': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  'W1': array([[-0.10243756,  0.36800669,  0.18942226,  0.08055432, -0.2808596 ,\n",
       "          -0.2808793 , -0.36082322,  0.29898157,  0.08256006,  0.16989055,\n",
       "          -0.39144112,  0.38367979,  0.27143828, -0.23487413, -0.25978883,\n",
       "          -0.25849914, -0.15983554,  0.02021354, -0.05556666, -0.17046069,\n",
       "           0.09132751, -0.29435203, -0.16971318, -0.1091151 , -0.03586871,\n",
       "           0.2328452 , -0.24521533,  0.01162237,  0.07545618, -0.37032169,\n",
       "           0.08781   , -0.26901593],\n",
       "         [-0.35513389,  0.36651351,  0.38018696,  0.25180538, -0.15953219,\n",
       "          -0.32849934,  0.15042564, -0.04886528, -0.30860449, -0.00393804,\n",
       "          -0.38017018,  0.33420871, -0.19695532,  0.13269889, -0.15373726,\n",
       "           0.01638547,  0.03813878, -0.25731526,  0.38341424,  0.22464501,\n",
       "           0.35884938,  0.32237518,  0.079935  ,  0.34445887, -0.33599447,\n",
       "          -0.24822895, -0.37132036, -0.14261719, -0.09089461, -0.18669273,\n",
       "           0.26841305, -0.11696042],\n",
       "         [-0.17886622,  0.03486121, -0.29318414,  0.2467428 , -0.34737794,\n",
       "           0.39754152,  0.22228692, -0.24599762, -0.4037395 ,  0.25757318,\n",
       "           0.16889831,  0.18698357,  0.22149131, -0.34779109, -0.11556225,\n",
       "          -0.3136416 ,  0.29647271,  0.1006725 , -0.13807118, -0.35635311,\n",
       "          -0.15433229, -0.14273722,  0.18747266,  0.11231521,  0.31615788,\n",
       "          -0.02268642, -0.3106    ,  0.17411364,  0.2129301 ,  0.05003262,\n",
       "           0.22124378, -0.00506587],\n",
       "         [ 0.01856128, -0.05916251, -0.38749366, -0.32015531, -0.38258647,\n",
       "           0.11137863, -0.15157771,  0.00699794,  0.33277663, -0.20470204,\n",
       "          -0.07317204,  0.20865663, -0.22143537, -0.34539446, -0.17166722,\n",
       "          -0.27661166,  0.35084666,  0.25157924,  0.10892371,  0.3032963 ,\n",
       "           0.24794721, -0.25591448,  0.32052308,  0.03212281,  0.25102384,\n",
       "           0.32340719, -0.14859954, -0.31839127, -0.22214001, -0.05951624,\n",
       "           0.25965797,  0.29453529]]),\n",
       "  'b2': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  'W2': array([[-0.24652393,  0.00537365, -0.0412945 , ..., -0.12907385,\n",
       "          -0.20344862,  0.19860788],\n",
       "         [ 0.20020903,  0.06655073, -0.0804851 , ..., -0.091539  ,\n",
       "          -0.16525363,  0.02840063],\n",
       "         [ 0.21807739,  0.0980149 ,  0.03503059, ..., -0.16335284,\n",
       "          -0.17178148, -0.12487855],\n",
       "         ...,\n",
       "         [-0.18326001, -0.20969924,  0.11396965, ...,  0.11140715,\n",
       "          -0.21616582,  0.10391755],\n",
       "         [ 0.02176911, -0.20913733, -0.02084968, ...,  0.24176074,\n",
       "          -0.17964424, -0.14899217],\n",
       "         [-0.15788758,  0.19699486,  0.07714628, ...,  0.17786863,\n",
       "          -0.13641022,  0.16852056]]),\n",
       "  'b3': array([[0., 0., 0., 0.]]),\n",
       "  'W3': array([[-0.13112954,  0.0848845 ,  0.11534263,  0.00751804],\n",
       "         [-0.11566269, -0.17071468, -0.27732685, -0.11647319],\n",
       "         [ 0.09099226,  0.26039186,  0.22052832,  0.15806603],\n",
       "         [ 0.17136326,  0.09801564, -0.14241083,  0.2419099 ],\n",
       "         [ 0.10143011,  0.03590709, -0.23110669, -0.03145369],\n",
       "         [-0.0235507 ,  0.21658306,  0.02771317, -0.07105266],\n",
       "         [ 0.2832616 , -0.23126643, -0.04601309, -0.27207789],\n",
       "         [ 0.14252429,  0.24837448, -0.1306773 ,  0.21288668],\n",
       "         [-0.12344077,  0.24403384,  0.15087585,  0.18114162],\n",
       "         [-0.28634677,  0.27495032,  0.13466264, -0.11599513],\n",
       "         [ 0.19568959, -0.12979575,  0.22144878, -0.23016154],\n",
       "         [ 0.1210075 ,  0.0241785 , -0.23969424, -0.15333792],\n",
       "         [-0.28967517, -0.01855459, -0.11806603,  0.05843305],\n",
       "         [-0.12045869, -0.11886576,  0.14447829, -0.26844316],\n",
       "         [ 0.23935529,  0.20927593,  0.09969084,  0.05538187],\n",
       "         [ 0.23306241, -0.18694173, -0.25012959, -0.15475402],\n",
       "         [ 0.17500558, -0.27644706,  0.04919459,  0.29433374],\n",
       "         [ 0.21131497,  0.01274064, -0.25923593,  0.1968652 ],\n",
       "         [ 0.058802  , -0.22876389, -0.24128473,  0.24335459],\n",
       "         [ 0.10051993,  0.19562551,  0.22514702,  0.04263913],\n",
       "         [ 0.01036468, -0.04133228, -0.10874993, -0.03885579],\n",
       "         [ 0.16270876,  0.06055154,  0.23319358, -0.03363728],\n",
       "         [ 0.06362069,  0.07800831,  0.05447623,  0.1203824 ],\n",
       "         [-0.15598776,  0.00734518, -0.2351255 , -0.0686105 ],\n",
       "         [-0.00732685,  0.09043469,  0.26765533,  0.05979564],\n",
       "         [ 0.14471635,  0.00372259,  0.07966967, -0.25490425],\n",
       "         [-0.14591314, -0.08207149, -0.01634138, -0.26992487],\n",
       "         [-0.21385755, -0.13259206,  0.28013216, -0.10019481],\n",
       "         [-0.0106692 , -0.18054486,  0.06581317, -0.13029359],\n",
       "         [-0.17407235,  0.00984561, -0.29377333, -0.29249115],\n",
       "         [-0.166898  , -0.27522852, -0.2328674 , -0.09573104],\n",
       "         [ 0.17976268,  0.04280327,  0.00752575, -0.12268592],\n",
       "         [ 0.25649993, -0.06118218, -0.24530345,  0.06954787],\n",
       "         [-0.22941418, -0.09195115,  0.00440335,  0.22232131],\n",
       "         [-0.0038339 ,  0.12015961,  0.29277683, -0.21892809],\n",
       "         [-0.13382942, -0.06263114, -0.04644098, -0.05286136],\n",
       "         [ 0.24215702,  0.12715434,  0.06410525, -0.11324948],\n",
       "         [ 0.19236015,  0.27034623,  0.19082021, -0.29611445],\n",
       "         [ 0.08103449, -0.26666532, -0.14400277, -0.26168132],\n",
       "         [ 0.06166369,  0.11085093, -0.22902847, -0.06900999],\n",
       "         [-0.02599939, -0.0777941 , -0.2251447 , -0.04815219],\n",
       "         [ 0.149222  , -0.25485942, -0.24941024, -0.08627871],\n",
       "         [ 0.26242418,  0.10014708,  0.10614577, -0.08203175],\n",
       "         [ 0.0556428 , -0.29102544,  0.0808531 ,  0.24552903],\n",
       "         [ 0.06687861,  0.22201005,  0.13305982, -0.22542189],\n",
       "         [ 0.23909289, -0.25757074,  0.02017969, -0.21260223],\n",
       "         [-0.2900895 , -0.04631855, -0.12176396, -0.00831695],\n",
       "         [ 0.04586357, -0.27105938, -0.22396942,  0.03483877],\n",
       "         [-0.09317248,  0.13614934,  0.09047472,  0.20531959],\n",
       "         [ 0.11435778, -0.04162714,  0.10275749, -0.13344347],\n",
       "         [-0.11506693,  0.17168277, -0.03183155,  0.17726434],\n",
       "         [ 0.19154743,  0.21242368,  0.24751821, -0.04100089],\n",
       "         [-0.10760914,  0.04883333, -0.07653499,  0.060047  ],\n",
       "         [ 0.1221362 ,  0.11192926, -0.07452669, -0.19791453],\n",
       "         [-0.04127172, -0.21233072,  0.23175217, -0.09156243],\n",
       "         [-0.2052815 , -0.28192604,  0.08663141,  0.0813321 ],\n",
       "         [-0.09469524, -0.25444105, -0.05368844, -0.11215352],\n",
       "         [ 0.10522534,  0.06284224, -0.08044331, -0.1675968 ],\n",
       "         [ 0.28993657, -0.02732711,  0.11185156, -0.21354336],\n",
       "         [-0.00856099, -0.28068501,  0.00324082,  0.27566742],\n",
       "         [-0.06879146, -0.27387718, -0.27865378, -0.06654578],\n",
       "         [-0.20197528, -0.28317105,  0.15221357, -0.024641  ],\n",
       "         [-0.12520726,  0.23768483, -0.22804744,  0.27085614],\n",
       "         [-0.11052024,  0.23074617,  0.06115718,  0.19409309]])}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_forward(A, W, b):\n",
    "    \"\"\"Dense (fully-connected) layer forward propagation.\"\"\"\n",
    "    cache = (A, W, b)\n",
    "    Z = A.dot(W) + b\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z, cache = dense_forward(X_train, model['var']['W1'], model['var']['b1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    \"\"\"ReLU forward propagation layer with cache returned.\"\"\"\n",
    "    cache = Z.copy()\n",
    "    A = np.maximum(0,Z)\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr(weight_init, 'glorot_uniform')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {}\n",
    "model = initialize_model(layer_dims=layer_dims,\n",
    "                          activation='RELU', weight_init='GLOROT_UNiform',\n",
    "                          dropout_rate=None, learning_rate=0.001, num_steps=3000, \n",
    "                          early_stopping=True)\n",
    "model = global_param_init(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in model['var'].items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "from layers import model_forward, model_backward\n",
    "from utils import predict, global_param_init, update_params, plot, log_csv\n",
    "from metrics import cat_xentropy_loss\n",
    "from preprocessing import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "layer_dims = [4, 32, 64, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(**kwargs):\n",
    "    for k,v in kwargs.items():\n",
    "        if type(v) == str:\n",
    "            model[k] = v.lower()\n",
    "        else:\n",
    "            model[k] = v\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {}\n",
    "model = initialize_model(layer_dims=layer_dims,\n",
    "                          activation='RELU', weight_init='GLOROT_UNiform',\n",
    "                          dropout_rate=None, learning_rate=0.001, num_steps=3000, \n",
    "                          early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import layers\n",
    "act = 'relu'\n",
    "getattr(layers, f'{act}')(np.arange(-10,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_train, X_test, y_train, y_test, num_steps):\n",
    "    losses = [] # initialize loss array\n",
    "    train_accs = [] # initialize training accuracy array\n",
    "    val_accs = [] # initialize validation accuracy array\n",
    "    t = tqdm.trange(num_steps) # tqdm object\n",
    "    best_epoch = num_steps # initialize best epoch value\n",
    "    # Training loop\n",
    "    for i in t:\n",
    "        probs, caches = model_forward(X_train, params, activation, dropout_rate) # forward propagation\n",
    "        loss = cat_xentropy_loss(probs, y_train) # calculate loss\n",
    "        grads = model_backward(probs, y_train, caches, activation, dropout_rate) # error backpropagation\n",
    "        params = update_params(params, grads, learning_rate) # weight updates\n",
    "        train_acc = predict(X_train, y_train, params, activation) # training accuracy\n",
    "        val_acc = predict(X_test, y_test, params, activation) # testing accuracy\n",
    "        t.set_postfix(loss=float(loss), train_acc=train_acc, val_acc=val_acc) # tqdm printing\n",
    "        losses.append(loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        # Record training logs\n",
    "        if early_stopping and val_acc > 0.99:\n",
    "            best_epoch = i\n",
    "            print()\n",
    "            print('Early Stopping at Epoch: {}'.format(i))      \n",
    "            break # stop training if maximum accuracy is achieved\n",
    "    print('Training Finished')\n",
    "    print('Training Accuracy Score: {:.2f}%'.format(train_acc*100))\n",
    "    print('Validation Accuracy Score: {:.2f}%'.format(val_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    a = model['lol'] if 'lol' in model else 42\n",
    "    print(model['activation'])\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dims = [4, 32, 64, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {}\n",
    "model = initialize_model(layer_dims=layer_dims,\n",
    "                          activation='relu', weight_init='glorot_uniform',\n",
    "                          dropout_rate=None, learning_rate=0.001, num_steps=3000, \n",
    "                          early_stopping=True, lol=1000)\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'layer_dims' in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model['params'] = global_param_init(layer_dims, weight_init)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
