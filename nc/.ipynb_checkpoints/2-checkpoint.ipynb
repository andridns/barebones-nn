{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.arange(0,10)\n",
    "y_pred = np.arange(1,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((y_true - y_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_forward(A, W, b):\n",
    "    \"\"\"Dense (fully-connected) layer forward propagation.\"\"\"\n",
    "    cache = (A, W, b)\n",
    "    Z = A.dot(W) + b\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z, cache = dense_forward(X_train, model['params']['W1'], model['params']['b1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    \"\"\"ReLU forward propagation layer with cache returned.\"\"\"\n",
    "    cache = Z.copy()\n",
    "    A = np.maximum(0,Z)\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {}\n",
    "model = initialize_model(layer_dims=layer_dims,\n",
    "                          activation='RELU', weight_init='GLOROT_UNiform',\n",
    "                          dropout_rate=None, learning_rate=0.001, num_steps=3000, \n",
    "                          early_stopping=True)\n",
    "model = global_param_init(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer_dims': [4, 32, 64, 3],\n",
       " 'activation': 'relu',\n",
       " 'weight_init': 'glorot_uniform',\n",
       " 'dropout_rate': None,\n",
       " 'learning_rate': 0.001,\n",
       " 'num_steps': 3000,\n",
       " 'early_stopping': True,\n",
       " 'params': {'b1': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  'W1': array([[-0.10243756,  0.36800669,  0.18942226,  0.08055432, -0.2808596 ,\n",
       "          -0.2808793 , -0.36082322,  0.29898157,  0.08256006,  0.16989055,\n",
       "          -0.39144112,  0.38367979,  0.27143828, -0.23487413, -0.25978883,\n",
       "          -0.25849914, -0.15983554,  0.02021354, -0.05556666, -0.17046069,\n",
       "           0.09132751, -0.29435203, -0.16971318, -0.1091151 , -0.03586871,\n",
       "           0.2328452 , -0.24521533,  0.01162237,  0.07545618, -0.37032169,\n",
       "           0.08781   , -0.26901593],\n",
       "         [-0.35513389,  0.36651351,  0.38018696,  0.25180538, -0.15953219,\n",
       "          -0.32849934,  0.15042564, -0.04886528, -0.30860449, -0.00393804,\n",
       "          -0.38017018,  0.33420871, -0.19695532,  0.13269889, -0.15373726,\n",
       "           0.01638547,  0.03813878, -0.25731526,  0.38341424,  0.22464501,\n",
       "           0.35884938,  0.32237518,  0.079935  ,  0.34445887, -0.33599447,\n",
       "          -0.24822895, -0.37132036, -0.14261719, -0.09089461, -0.18669273,\n",
       "           0.26841305, -0.11696042],\n",
       "         [-0.17886622,  0.03486121, -0.29318414,  0.2467428 , -0.34737794,\n",
       "           0.39754152,  0.22228692, -0.24599762, -0.4037395 ,  0.25757318,\n",
       "           0.16889831,  0.18698357,  0.22149131, -0.34779109, -0.11556225,\n",
       "          -0.3136416 ,  0.29647271,  0.1006725 , -0.13807118, -0.35635311,\n",
       "          -0.15433229, -0.14273722,  0.18747266,  0.11231521,  0.31615788,\n",
       "          -0.02268642, -0.3106    ,  0.17411364,  0.2129301 ,  0.05003262,\n",
       "           0.22124378, -0.00506587],\n",
       "         [ 0.01856128, -0.05916251, -0.38749366, -0.32015531, -0.38258647,\n",
       "           0.11137863, -0.15157771,  0.00699794,  0.33277663, -0.20470204,\n",
       "          -0.07317204,  0.20865663, -0.22143537, -0.34539446, -0.17166722,\n",
       "          -0.27661166,  0.35084666,  0.25157924,  0.10892371,  0.3032963 ,\n",
       "           0.24794721, -0.25591448,  0.32052308,  0.03212281,  0.25102384,\n",
       "           0.32340719, -0.14859954, -0.31839127, -0.22214001, -0.05951624,\n",
       "           0.25965797,  0.29453529]]),\n",
       "  'b2': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  'W2': array([[-0.24652393,  0.00537365, -0.0412945 , ..., -0.12907385,\n",
       "          -0.20344862,  0.19860788],\n",
       "         [ 0.20020903,  0.06655073, -0.0804851 , ..., -0.091539  ,\n",
       "          -0.16525363,  0.02840063],\n",
       "         [ 0.21807739,  0.0980149 ,  0.03503059, ..., -0.16335284,\n",
       "          -0.17178148, -0.12487855],\n",
       "         ...,\n",
       "         [-0.18326001, -0.20969924,  0.11396965, ...,  0.11140715,\n",
       "          -0.21616582,  0.10391755],\n",
       "         [ 0.02176911, -0.20913733, -0.02084968, ...,  0.24176074,\n",
       "          -0.17964424, -0.14899217],\n",
       "         [-0.15788758,  0.19699486,  0.07714628, ...,  0.17786863,\n",
       "          -0.13641022,  0.16852056]]),\n",
       "  'b3': array([[0., 0., 0.]]),\n",
       "  'W3': array([[-0.1321045 ,  0.08551562,  0.11620021],\n",
       "         [ 0.00757394, -0.11652265, -0.17198395],\n",
       "         [-0.27938879, -0.11733918,  0.09166879],\n",
       "         [ 0.26232789,  0.22216796,  0.15924126],\n",
       "         [ 0.17263735,  0.09874439, -0.14346966],\n",
       "         [ 0.24370851,  0.10218425,  0.03617406],\n",
       "         [-0.23282498, -0.03168755, -0.0237258 ],\n",
       "         [ 0.21819336,  0.02791922, -0.07158094],\n",
       "         [ 0.28536767, -0.23298591, -0.0463552 ],\n",
       "         [-0.2741008 ,  0.14358396,  0.25022116],\n",
       "         [-0.13164889,  0.2144695 , -0.12435855],\n",
       "         [ 0.24584824,  0.15199762,  0.18248841],\n",
       "         [-0.28847578,  0.27699459,  0.13566386],\n",
       "         [-0.11685756,  0.19714455, -0.13076079],\n",
       "         [ 0.22309526, -0.23187281,  0.1219072 ],\n",
       "         [ 0.02435827, -0.24147638, -0.15447799],\n",
       "         [-0.29182892, -0.01869255, -0.11894385],\n",
       "         [ 0.05886751, -0.12135431, -0.11974953],\n",
       "         [ 0.14555249, -0.27043904,  0.24113491],\n",
       "         [ 0.2108319 ,  0.10043204,  0.05579363],\n",
       "         [ 0.23479524, -0.18833165, -0.25198931],\n",
       "         [-0.15590462,  0.17630675, -0.27850245],\n",
       "         [ 0.04956035,  0.29652213,  0.2128861 ],\n",
       "         [ 0.01283537, -0.26116336,  0.1983289 ],\n",
       "         [ 0.05923919, -0.23046476, -0.24307869],\n",
       "         [ 0.24516395,  0.10126731,  0.19707999],\n",
       "         [ 0.22682099,  0.04295615,  0.01044174],\n",
       "         [-0.04163958, -0.10955849, -0.03914468],\n",
       "         [ 0.16391851,  0.06100174,  0.23492739],\n",
       "         [-0.03388738,  0.06409371,  0.07858831],\n",
       "         [ 0.05488127,  0.12127745, -0.15714754],\n",
       "         [ 0.00739979, -0.23687367, -0.06912062],\n",
       "         [-0.00738133,  0.09110707,  0.26964536],\n",
       "         [ 0.06024023,  0.14579232,  0.00375027],\n",
       "         [ 0.08026201, -0.25679947, -0.14699801],\n",
       "         [-0.0826817 , -0.01646288, -0.27193177],\n",
       "         [-0.21544759, -0.13357789,  0.28221496],\n",
       "         [-0.10093976, -0.01074853, -0.18188722],\n",
       "         [ 0.06630249, -0.13126232, -0.17536658],\n",
       "         [ 0.00991881, -0.29595755, -0.29466583],\n",
       "         [-0.16813889, -0.27727486, -0.23459878],\n",
       "         [-0.0964428 ,  0.18109922,  0.04312152],\n",
       "         [ 0.0075817 , -0.1235981 ,  0.25840702],\n",
       "         [-0.06163707, -0.24712729,  0.07006497],\n",
       "         [-0.23111988, -0.09263482,  0.00443609],\n",
       "         [ 0.22397428, -0.00386241,  0.121053  ],\n",
       "         [ 0.29495364, -0.22055583, -0.13482444],\n",
       "         [-0.06309681, -0.04678627, -0.05325438],\n",
       "         [ 0.24395747,  0.12809974,  0.06458188],\n",
       "         [-0.1140915 ,  0.19379036,  0.27235627],\n",
       "         [ 0.19223897, -0.29831608,  0.08163698],\n",
       "         [-0.26864799, -0.14507344, -0.26362693],\n",
       "         [ 0.06212216,  0.11167511, -0.23073131],\n",
       "         [-0.06952308, -0.02619269, -0.0783725 ],\n",
       "         [-0.22681866, -0.0485102 ,  0.15033147],\n",
       "         [-0.25675432, -0.25126461, -0.0869202 ],\n",
       "         [ 0.26437531,  0.10089167,  0.10693497],\n",
       "         [-0.08264166,  0.05605651, -0.29318923],\n",
       "         [ 0.08145425,  0.24735455,  0.06737585],\n",
       "         [ 0.2236607 ,  0.13404913, -0.22709791],\n",
       "         [ 0.24087056, -0.25948579,  0.02032972],\n",
       "         [-0.21418294, -0.29224633, -0.04666293],\n",
       "         [-0.12266928, -0.00837878,  0.04620456],\n",
       "         [-0.27307472, -0.22563464,  0.0350978 ]])}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_param_init(model):\n",
    "    \"\"\"Initialize weight and biases parameters in the network.\n",
    "\n",
    "    Args:\n",
    "        model['layer_dims']: list containing number of input, hidden and output neurons in sequence\n",
    "        model['weight_init'] (str): weight initialization method\n",
    "    \n",
    "    Returns:\n",
    "        model['params']: dictionary of model weights (W) and biases (b) in all layers\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    model['params'] = {}\n",
    "    L = len(model['layer_dims']) # no of layers\n",
    "    for l in range(1, L):\n",
    "        model['params']['b' + str(l)] = np.zeros((1, model['layer_dims'][l])) # bias initialization\n",
    "        # typical weight initialization methods\n",
    "        if model['weight_init'].lower() == 'glorot_uniform':\n",
    "            limit = np.sqrt(6. / (model['layer_dims'][l-1] + model['layer_dims'][l]))\n",
    "            model['params']['W' + str(l)] = np.random.uniform(-limit, limit, (model['layer_dims'][l-1], model['layer_dims'][l]))\n",
    "        elif model['weight_init'].lower() == 'glorot_normal':\n",
    "            stddev = np.sqrt(2. / (model['layer_dims'][l-1] + model['layer_dims'][l]))\n",
    "            model['params']['W' + str(l)] = np.random.randn(model['layer_dims'][l-1], model['layer_dims'][l]) * stddev\n",
    "        elif model['weight_init'].lower() == 'he_uniform':\n",
    "            limit = np.sqrt(6. / model['layer_dims'][l-1])\n",
    "            model['params']['W' + str(l)] = np.random.uniform(-limit, limit, (model['layer_dims'][l-1], model['layer_dims'][l]))\n",
    "        elif model['weight_init'].lower() == 'he_normal':\n",
    "            stddev = np.sqrt(2. / model['layer_dims'][l-1])\n",
    "            model['params']['W' + str(l)] = np.random.randn(model['layer_dims'][l-1], model['layer_dims'][l]) * stddev\n",
    "                                   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "from layers import model_forward, model_backward\n",
    "from utils import predict, global_param_init, update_params, plot, log_csv\n",
    "from metrics import cat_xentropy_loss\n",
    "from preprocessing import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "layer_dims = [4, 32, 64, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(**kwargs):\n",
    "    for k,v in kwargs.items():\n",
    "        if type(v) == str:\n",
    "            model[k] = v.lower()\n",
    "        else:\n",
    "            model[k] = v\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {}\n",
    "model = initialize_model(layer_dims=layer_dims,\n",
    "                          activation='RELU', weight_init='GLOROT_UNiform',\n",
    "                          dropout_rate=None, learning_rate=0.001, num_steps=3000, \n",
    "                          early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer_dims': [4, 32, 64, 3],\n",
       " 'activation': 'relu',\n",
       " 'weight_init': 'glorot_uniform',\n",
       " 'dropout_rate': None,\n",
       " 'learning_rate': 0.001,\n",
       " 'num_steps': 3000,\n",
       " 'early_stopping': True}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  2,  3,  4,  5,  6,\n",
       "         7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,\n",
       "        24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n",
       "        41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57,\n",
       "        58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74,\n",
       "        75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91,\n",
       "        92, 93, 94, 95, 96, 97, 98, 99]),\n",
       " array([-10,  -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2,\n",
       "          3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,\n",
       "         16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
       "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
       "         55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,\n",
       "         68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,\n",
       "         81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
       "         94,  95,  96,  97,  98,  99]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import layers\n",
    "act = 'relu'\n",
    "getattr(layers, f'{act}')(np.arange(-10,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_train, X_test, y_train, y_test, num_steps):\n",
    "    losses = [] # initialize loss array\n",
    "    train_accs = [] # initialize training accuracy array\n",
    "    val_accs = [] # initialize validation accuracy array\n",
    "    t = tqdm.trange(num_steps) # tqdm object\n",
    "    best_epoch = num_steps # initialize best epoch value\n",
    "    # Training loop\n",
    "    for i in t:\n",
    "        probs, caches = model_forward(X_train, params, activation, dropout_rate) # forward propagation\n",
    "        loss = cat_xentropy_loss(probs, y_train) # calculate loss\n",
    "        grads = model_backward(probs, y_train, caches, activation, dropout_rate) # error backpropagation\n",
    "        params = update_params(params, grads, learning_rate) # weight updates\n",
    "        train_acc = predict(X_train, y_train, params, activation) # training accuracy\n",
    "        val_acc = predict(X_test, y_test, params, activation) # testing accuracy\n",
    "        t.set_postfix(loss=float(loss), train_acc=train_acc, val_acc=val_acc) # tqdm printing\n",
    "        losses.append(loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        # Record training logs\n",
    "        if early_stopping and val_acc > 0.99:\n",
    "            best_epoch = i\n",
    "            print()\n",
    "            print('Early Stopping at Epoch: {}'.format(i))      \n",
    "            break # stop training if maximum accuracy is achieved\n",
    "    print('Training Finished')\n",
    "    print('Training Accuracy Score: {:.2f}%'.format(train_acc*100))\n",
    "    print('Validation Accuracy Score: {:.2f}%'.format(val_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    a = model['lol'] if 'lol' in model else 42\n",
    "    print(model['activation'])\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dims = [4, 32, 64, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {}\n",
    "model = initialize_model(layer_dims=layer_dims,\n",
    "                          activation='relu', weight_init='glorot_uniform',\n",
    "                          dropout_rate=None, learning_rate=0.001, num_steps=3000, \n",
    "                          early_stopping=True, lol=1000)\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'layer_dims' in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model['params'] = global_param_init(layer_dims, weight_init)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
